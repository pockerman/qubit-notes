# qubit-note: Solving Markov Decision Process

## Overview

In this qubit-note we will give a very high level overview of some popular approaches that can be
used to solve an MDP.

In this qubit note we will review five different paradigms which can be used to solve an MDP.
Namely, we will discuss

- Multi-armed bandits (MAB)
- Temporal Difference Learning
- Monte Carlo Estimation
- Dynamic Programming
- Tree Search


## Summary

## References